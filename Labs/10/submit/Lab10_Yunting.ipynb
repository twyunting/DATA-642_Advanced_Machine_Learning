{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab10_Yunting.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1n77WTmRYuXiiHQ_RxcK1sBxXedAYe3dS","authorship_tag":"ABX9TyMHMJfXVozJRPvE2FSwXpwx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"U2G9GgIsQyZo"},"source":["# Lab08 - Neural Networks and Deep Learning\n","Author: [Yunting Chiu](https://www.linkedin.com/in/yuntingchiu/) "]},{"cell_type":"markdown","metadata":{"id":"QqGwczwKQ_ib"},"source":["# Install the required packages"]},{"cell_type":"code","metadata":{"id":"NQIvcuZnWUe5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQMnIvrvWWNE"},"source":[""]},{"cell_type":"code","metadata":{"id":"Fy-u2mBmT2mu"},"source":["def load_minst_data():\n","  # load the data\n","  (x_train, y_train), (x_test, y_test) = minst.load.data()\n","  # normalize the inputs to be in the range[-1, 1]\n","  x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n","  # convert x_train with a shape of (60000, 28, 28) to (60000, 784) so we have 784 columns pre row\n","  x_train = x_train.reshape(60000, 784)\n","  return (x_train, y_train, x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaJYUoDdUkcB"},"source":["# We will use the Adam optimizer\n","def get_optimizer():\n","  return Adam(lr = 0.0002, beta_1 = 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ae1XxbpPUvpJ"},"source":["def get_generator(optimizer):\n","  generator = Sequential()\n","  generator.add(Dense(256, input_dim = random_dim, kernel_initializer = initializers.RandomNormal(stddev = 0.02)))\n","  generator.add(LeakyReLU(0.2))\n","\n","  generator.add(Dense(512))\n","  generator.add(LeakyReLU(0.2))\n","\n","  generator.add(Dense(1024))\n","  generator.add(LeakyReLU(0.2))\n","\n","  generator.add(Dense(784, activation = 'tanh'))\n","  generator.compile(loss = 'binary_crossentropy', optimzer = )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5IEGQ9Tv-xue"},"source":["# References\n"]},{"cell_type":"markdown","metadata":{"id":"YyjMxsO7ch3F"},"source":["# Testing Zone"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"ylvONl6gpFrN","executionInfo":{"status":"ok","timestamp":1636307553908,"user_tz":300,"elapsed":46,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"5f40b869-6147-4a42-a8f9-2c7c8b558433"},"source":["\"\"\"\n","from sklearn.neural_network import MLPClassifier\n","clf = MLPClassifier(hidden_layer_sizes=2, max_iter=6000, learning_rate_init=0.01, activation='relu').fit(x_train, y_train)\n","#clf.predict_proba(x_test[:1])\n","#clf.predict(x_test[:5, :])\n","clf.score(x_test, y_test)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nfrom sklearn.neural_network import MLPClassifier\\nclf = MLPClassifier(hidden_layer_sizes=2, max_iter=6000, learning_rate_init=0.01, activation='relu').fit(x_train, y_train)\\n#clf.predict_proba(x_test[:1])\\n#clf.predict(x_test[:5, :])\\nclf.score(x_test, y_test)\\n\""]},"metadata":{},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"_9hQuLkaohUt","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1636307553910,"user_tz":300,"elapsed":44,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"dadb7288-e65d-4490-a394-2978e21dbcfe"},"source":["\"\"\"\n","# Initialize variables\n","np.random.seed(4321)\n","learning_rate = 0.0001\n","iterations = 6000\n","N = y_train.size # 400\n","\n","# number of input features\n","input_size = 2\n","\n","# number of hidden layers neurons\n","hidden_size = 2\n","\n","# number of neurons at the output layer\n","output_size = 2\n","\n","results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])\n","\n","# initializing weight for the hidden layer\n","W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))   \n","\n","\n","# initializing weight for the output layer\n","W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size)) \n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# Initialize variables\\nnp.random.seed(4321)\\nlearning_rate = 0.0001\\niterations = 6000\\nN = y_train.size # 400\\n\\n# number of input features\\ninput_size = 2\\n\\n# number of hidden layers neurons\\nhidden_size = 2\\n\\n# number of neurons at the output layer\\noutput_size = 2\\n\\nresults = pd.DataFrame(columns=[\"mse\", \"accuracy\"])\\n\\n# initializing weight for the hidden layer\\nW1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))   \\n\\n\\n# initializing weight for the output layer\\nW2 = np.random.normal(scale=0.5, size=(hidden_size , output_size)) \\n'"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","metadata":{"id":"jK_eu9ycFeYW","colab":{"base_uri":"https://localhost:8080/","height":103},"executionInfo":{"status":"ok","timestamp":1636307553912,"user_tz":300,"elapsed":44,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"62e111bc-f444-41d6-a63d-4341ca71fc38"},"source":["\"\"\"\n","# ref: https://machinelearninggeek.com/backpropagation-neural-network-using-python/\n","for itr in range(iterations):    \n","\n","  # feedforward propagation\n","  # on hidden layer\n","  Z1 = np.dot(x_train, W1)\n","  A1 = ReLU(Z1)\n","\n","  # on output layer\n","  Z2 = np.dot(A1, W2)\n","  A2 = ReLU(Z2)\n","    \n","  # Calculating error\n","  mse = mean_squared_error(A2, y_train)\n","  acc = accuracy(A2, y_train)\n","  results=results.append({\"mse\":mse, \"accuracy\":acc},ignore_index= True)\n","\n","  # backpropagation\n","  E1 = A2 - y_train\n","  dW1 = E1 * A2 * (1 - A2)\n","\n","  E2 = np.dot(dW1, W2.T)\n","  dW2 = E2 * A1 * (1 - A1)\n","\n","  # weight updates\n","  W2_update = np.dot(A1.T, dW1) / N\n","  W1_update = np.dot(x_train.T, dW2) / N\n","\n","  W2 = W2 - learning_rate * W2_update\n","  W1 = W1 - learning_rate * W1_update\n","\n","results.mse.plot(title=\"Mean Squared Error\")\n","results.accuracy.plot(title=\"Accuracy\")\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# ref: https://machinelearninggeek.com/backpropagation-neural-network-using-python/\\nfor itr in range(iterations):    \\n\\n  # feedforward propagation\\n  # on hidden layer\\n  Z1 = np.dot(x_train, W1)\\n  A1 = ReLU(Z1)\\n\\n  # on output layer\\n  Z2 = np.dot(A1, W2)\\n  A2 = ReLU(Z2)\\n    \\n  # Calculating error\\n  mse = mean_squared_error(A2, y_train)\\n  acc = accuracy(A2, y_train)\\n  results=results.append({\"mse\":mse, \"accuracy\":acc},ignore_index= True)\\n\\n  # backpropagation\\n  E1 = A2 - y_train\\n  dW1 = E1 * A2 * (1 - A2)\\n\\n  E2 = np.dot(dW1, W2.T)\\n  dW2 = E2 * A1 * (1 - A1)\\n\\n  # weight updates\\n  W2_update = np.dot(A1.T, dW1) / N\\n  W1_update = np.dot(x_train.T, dW2) / N\\n\\n  W2 = W2 - learning_rate * W2_update\\n  W1 = W1 - learning_rate * W1_update\\n\\nresults.mse.plot(title=\"Mean Squared Error\")\\nresults.accuracy.plot(title=\"Accuracy\")\\n'"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"fvL-P8kRFPxy","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1636307553913,"user_tz":300,"elapsed":43,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"2b2aa6f5-3de7-4059-c42f-7abafe6768ae"},"source":["\"\"\"\n","# rectified linear function (ReLU)\n","def ReLU(x):\n","  return np.maximum(0, x)\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def mean_squared_error(y_pred, y_true):\n","    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\n","    \n","def accuracy(y_pred, y_true):\n","    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n","    return acc.mean()\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# rectified linear function (ReLU)\\ndef ReLU(x):\\n  return np.maximum(0, x)\\n\\ndef sigmoid(x):\\n    return 1 / (1 + np.exp(-x))\\n\\ndef mean_squared_error(y_pred, y_true):\\n    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\\n    \\ndef accuracy(y_pred, y_true):\\n    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\\n    return acc.mean()\\n'"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"FJp47fJkZTlm","executionInfo":{"status":"ok","timestamp":1636307553915,"user_tz":300,"elapsed":43,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"5c66d38a-6c59-4072-faa6-b9139b7edacc"},"source":["\"\"\"\n","#Create testing data\n","w11_test = np.random.multivariate_normal(mean = [-5, 5], cov = [[1, 0], [0,1]],size = 50)\n","w12_test = np.random.multivariate_normal(mean = [5, -5], cov = [[1, 0], [0,1]],size = 50)\n","w21_test = np.random.multivariate_normal(mean = [-5, -5], cov = [[1, 0], [0,1]],size = 50)\n","w22_test = np.random.multivariate_normal(mean = [0, 0], cov = [[1, 0], [0, 1]],size = 50)\n","w23_test = np.random.multivariate_normal(mean = [5, 5], cov = [[1, 0], [0, 1]],size= 50)\n","W1_test = np.vstack((w11_test, w12_test))\n","W2_test = np.vstack((w21_test, w22_test, w23_test))\n","X2 = np.vstack((W1_test, W2_test))\n","y2 = np.concatenate((np.ones(shape=(1, 100)), np.zeros(shape=(1, 150))),axis=-1) # Class labels\n","print(X2.shape)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n#Create testing data\\nw11_test = np.random.multivariate_normal(mean = [-5, 5], cov = [[1, 0], [0,1]],size = 50)\\nw12_test = np.random.multivariate_normal(mean = [5, -5], cov = [[1, 0], [0,1]],size = 50)\\nw21_test = np.random.multivariate_normal(mean = [-5, -5], cov = [[1, 0], [0,1]],size = 50)\\nw22_test = np.random.multivariate_normal(mean = [0, 0], cov = [[1, 0], [0, 1]],size = 50)\\nw23_test = np.random.multivariate_normal(mean = [5, 5], cov = [[1, 0], [0, 1]],size= 50)\\nW1_test = np.vstack((w11_test, w12_test))\\nW2_test = np.vstack((w21_test, w22_test, w23_test))\\nX2 = np.vstack((W1_test, W2_test))\\ny2 = np.concatenate((np.ones(shape=(1, 100)), np.zeros(shape=(1, 150))),axis=-1) # Class labels\\nprint(X2.shape)\\n'"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","metadata":{"id":"qWZoyFcw971A"},"source":["# Output"]},{"cell_type":"code","metadata":{"id":"Zh6y-Cbx986W"},"source":["# should access the Google Drive files before running the chunk\n","%%capture\n","!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic \n","!jupyter nbconvert --to pdf \"/content/drive/MyDrive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/GitHub/Labs/08/submit/Lab8_Yunting.ipynb\""],"execution_count":null,"outputs":[]}]}