{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab4_Yunting.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1S9EHIlm3dFNDPfK8QHSI9_u5-4fonKzT","authorship_tag":"ABX9TyPdF7+dS4afoUr22PR6gxDo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sbWwM5jwtCIC"},"source":["# Lab04 - Sparsity Aware Learning\n","Author: [Yunting Chiu](https://www.linkedin.com/in/yuntingchiu/)\n","\n","# Exercise 1\n"]},{"cell_type":"code","metadata":{"id":"9VIbhUsAtTPo","executionInfo":{"status":"ok","timestamp":1633363253549,"user_tz":240,"elapsed":244,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}}},"source":["# Install the libraries\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from functools import reduce\n","%matplotlib inline\n","plt.style.use(['ggplot'])"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_GjigF5Fn2cG"},"source":["## 1A"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQWNSVFrs6E4","executionInfo":{"status":"ok","timestamp":1633363253549,"user_tz":240,"elapsed":16,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"3f52a3b6-c417-4930-bc1f-0b95b92b34f8"},"source":["X = np.array([[0.5, 2, 1.5], [2, 2.3, 3.5]]) # matrix X\n","theta = np.array([2.5, 0, 0], ndmin = 2).T \n","y = np.dot(X, theta)\n","print(theta)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.5]\n"," [0. ]\n"," [0. ]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOGjdpiQxCqG","executionInfo":{"status":"ok","timestamp":1633363253550,"user_tz":240,"elapsed":15,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"3b7a424b-13c3-4d46-96bc-ca6b2cf62c00"},"source":["print(X)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.5 2.  1.5]\n"," [2.  2.3 3.5]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5hHN9uFxCfn","executionInfo":{"status":"ok","timestamp":1633363253550,"user_tz":240,"elapsed":10,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"c2c533a5-98af-4dfa-db53-f2c8a30c988d"},"source":["print(y)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.25]\n"," [5.  ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ejq79D56vmrn"},"source":["According to the textbook 9.10, we can know the L2 minimizer accepts the closed from the following solution: \n","\n","$$\n","\\hat{\\theta} = X^T (XX^T)^{-1} y\n","$$\n","where $X^T (XX^T)^{-1}$ (a m Ã— n matrix) is called a pseudo-inverse."]},{"cell_type":"code","metadata":{"id":"K8PDGrnfvgST","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633363253551,"user_tz":240,"elapsed":9,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"07e0bfad-5fc9-412b-ced6-98e18ace6f31"},"source":["# theta2 = np.dot(np.dot(X.T, np.linalg.inv(np.dot(X, X.T))), y)\n","theta2 = np.dot(np.dot(X.T, np.linalg.inv(np.dot(X, X.T))), y)\n","error_L2 = np.linalg.norm(y - np.dot(X, theta2))\n","error_theta = np.linalg.norm(theta2 - theta)\n","print('The L2 norm minimized solution is {}'.format(theta2))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["The L2 norm minimized solution is [[ 1.08637128]\n"," [-0.49775659]\n"," [ 1.13488503]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsMv4_6oqlvW","executionInfo":{"status":"ok","timestamp":1633363253551,"user_tz":240,"elapsed":7,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"06398616-c808-452d-9de0-ad198f7d9835"},"source":["print(\" The error achieved with L2 norm minimization is {}\".format(error_L2))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" The error achieved with L2 norm minimization is 4.636427468134552e-15\n"]}]},{"cell_type":"markdown","metadata":{"id":"xWodea2MY_Pt"},"source":["There is an existing funcation called `numpy.linalg.pinv` of pseudoinverse of X matrix, the outcome is also the same as the previous formula."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2TMoDHiwPTB","executionInfo":{"status":"ok","timestamp":1633363253814,"user_tz":240,"elapsed":268,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"453a7680-9117-4531-aed8-5cb2bbec29aa"},"source":["pesu_X_ex1 = np.dot(X.T, np.linalg.inv((np.dot(X, X.T))))\n","print(pesu_X_ex1)\n","print(\"---------------------------\")\n","pesu_X_ex2 = np.linalg.pinv(X)\n","print(pesu_X_ex2)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.49040942  0.33987661]\n"," [ 0.81323612 -0.30286035]\n"," [-0.25417835  0.29052159]]\n","---------------------------\n","[[-0.49040942  0.33987661]\n"," [ 0.81323612 -0.30286035]\n"," [-0.25417835  0.29052159]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TTq-EPbErSQ3"},"source":["## 1B"]},{"cell_type":"markdown","metadata":{"id":"8NoayvB0yknu"},"source":["We need to estimate the smallest number of parameters that can be explained the obtained observations. Consider all possible combinations of zero in $\\theta$, removing the respective columns of X and check whether the system of equations is satisifed. \n","\n","Let's start checking for possible 1-sparse solution.\n","\n","### Check solution [x, 0, 0]\n","This one has the ideal solution, the $\\theta_0$ lead to zero estimation error."]},{"cell_type":"code","metadata":{"id":"1-ZMrfjzzdt9"},"source":["subX_11 = np.array(X[:, 0], ndmin = 2).T # ndmin = Number of array dimensions\n","# print(subX_11)\n","theta_11 = np.zeros((3, 1))\n","theta_11[0] = np.dot(np.linalg.inv(np.dot(subX_11.T, subX_11)), np.dot(subX_11.T, y))\n","print(theta_11)\n","error1 = np.linalg.norm(y - np.dot(X, theta_11)) #check that theta_11 is a solution\n","error_theta1 = np.linalg.norm(theta_11 - theta)\n","print('Achieved error: %.20f'% error1)\n","print('Achieved error in theta %.20f'% error_theta1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0w2dfvno_Dtj"},"source":["### Check solution [0, x, 0]"]},{"cell_type":"code","metadata":{"id":"qzX7mcKA9lyc"},"source":["subX_12 = np.array(X[:, 1], ndmin = 2).T # ndmin = Number of array dimensions\n","# print(subX_22)\n","theta_12 = np.zeros((3, 1))\n","theta_12[1] = np.dot(np.linalg.inv(np.dot(subX_12.T, subX_12)), np.dot(subX_12.T, y))\n","print(theta_12)\n","error2 = np.linalg.norm(y - np.dot(X, theta_12)) #check that theta_22 is a solution\n","error_theta2 = np.linalg.norm(theta_12 - theta)\n","print('Achieved error: %.20f'% error2)\n","print('Achieved error in theta %.20f'% error_theta2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"im4nIcHhCXt6"},"source":["### Check solution [0, 0, x]"]},{"cell_type":"code","metadata":{"id":"z_FVEwf0_FFD"},"source":["subX_13 = np.array(X[:, 2], ndmin = 2).T # ndmin = Number of array dimensions\n","# print(subX_22)\n","theta_13 = np.zeros((3, 1))\n","theta_13[2] = np.dot(np.linalg.inv(np.dot(subX_13.T, subX_13)), np.dot(subX_13.T, y))\n","print(theta_13)\n","error3 = np.linalg.norm(y - np.dot(X, theta_13)) # check that theta2 is a solution\n","error_theta3 = np.linalg.norm(theta_13 - theta)\n","print('Achieved error: %.20f'% error3)\n","print('Achieved error in theta %.20f'% error_theta3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBA-YeZXUQLX","executionInfo":{"status":"ok","timestamp":1633363253816,"user_tz":240,"elapsed":11,"user":{"displayName":"Yunting Chiu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_QuRP-FvpZwye5zw3rmJmceg28bQqANBEfLr_13E=s64","userId":"09054757205289220354"}},"outputId":"7a9148e0-2704-4cc6-8b08-ff1227841e88"},"source":["theta0 = theta_11 # because this combination has the lowest error\n","print(\"With zero estimation error of {}, we can skip for searching 2-sparse solutions\".format(theta0))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["With zero estimation error of [[2.5]\n"," [0. ]\n"," [0. ]], we can skip for searching 2-sparse solutions\n"]}]},{"cell_type":"markdown","metadata":{"id":"EVqoRqZdDmzD"},"source":["## 1C\n","As the $\\theta_2$ is the smaller one in L2 norms, which makes sense."]},{"cell_type":"code","metadata":{"id":"OPDvL0eTDn6F"},"source":["print(\"L2 norm of theta 0 is {}\".format(np.linalg.norm(theta0)))\n","print(\"L2 norm of theta 2 is {}\".format(np.linalg.norm(theta2)))\n","if np.linalg.norm(theta0) > np.linalg.norm(theta2):\n","  print(\"theta2 is the smaller one\")\n","else:\n","  print(\"theta0 is the smaller one\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rlvy3lW-lxYK"},"source":["# Exercise 2 Image Denoising"]},{"cell_type":"markdown","metadata":{"id":"skEEModDEHTf"},"source":["## 2A"]},{"cell_type":"code","metadata":{"id":"aZCPJraLEINx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QzrIm0V7SMqA"},"source":["# Testing Zone"]},{"cell_type":"code","metadata":{"id":"VzRBg1CN0lad"},"source":["print('Check solution [x, 0, 0]')\n","theta_11 = np.zeros((3, 1))\n","# print(theta_11)\n","subX_11 = np.array(X[:, 0], ndmin = 2).T\n","\n","theta_11[0] = np.dot(np.linalg.inv(np.dot(subX_11.T, subX_11)), np.dot(subX_11.T, y))\n","print(theta_11)\n","error1 = np.linalg.norm(y - np.dot(X, theta_11)) #check that theta_11 is a solution\n","error_theta1 = np.linalg.norm(theta_11 - theta)\n","\n","print('Achieved error: %.20f'% error1)\n","print('Achieved error in theta %.20f'% error_theta1)\n","print('--------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4d6wRF3srv-t"},"source":["# Output"]},{"cell_type":"code","metadata":{"id":"U988BiZHr471"},"source":["# should access the Google Drive files before running the chunk\n","%%capture\n","!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic \n","!jupyter nbconvert --to pdf \"/content/drive/MyDrive/American_University/2021_Fall/DATA-642-001_Advanced Machine Learning/GitHub/Labs/04/submit/Lab4_Yunting.ipynb\""],"execution_count":null,"outputs":[]}]}